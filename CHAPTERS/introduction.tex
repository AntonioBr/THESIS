\chapter{Introduction}

Nowadays every aspect of life is characterized by the need to make choices. Each choice is conditioned by a variable number of parameters. In many applicative domains (recommendation systems, medical analysis tools, real time game engines, speech recognizers...), this number could be very high.  The possibility to manage in an efficient way such a number of parameters is guaranteed by a significant number of mathematical techniques increasingly performing and refined.  \\

Every decisional problem can be translated into a mathematical model that represents the essence of the problem itself. A crucial step in formulating a model is the construction of the \textit{objective function}. This requires developing a quantitative measure of performance relative to each of the decision makerâ€™s ultimate objectives identified while the problem was being defined.~\cite{HillLieb01} \\

However it is not always possible to define the objective function in advance. It could be unknown or, at least, partially unknown at the time the problem is dealt with. In those cases the optimization process of the objective function takes the name of \textit{black-box optimization}. \\

Mathematically, the problem of finding a global maximizer (or minimizer) of an unknown objective function \textit{f} is formalized as:

\begin{equation}
x^* = \arg \max_{x \in \mathcal{X}} f(x)
\end{equation}

where $\mathcal{X}$ is some design space of interest. In global optimization, $\mathcal{X}$ is often a compact subset of $\mathbb{R}^d$ ~\cite{DBLP:journals/pieee/ShahriariSWAF16}. \\

Bayesian Optimization (BO) based on Gaussian Processes (GPs) represents one of the best known black-box optimization techniques. It represents a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years \cite{Adams2008GaussianPP}. Bayesian Optimization is a Sequential Model Based Optimization (SMBO) method that identify the next promising point where to evaluate the black-box objective function depending on the maximum value of an \textit{acquisition function} computed according to the current GP (probabilistic surrogate model of the black-box objective function).\\

In this thesis, an innovative approach to black-box optimization based on the Reinforcement Learning (RL) technique is proposed. RL is the problem faced by a learner that must refine its behaviour through trial-and-error interactions with a dynamic environment. It can be considered the problem of mapping situations, i.e. states, to actions in order to maximize a numerical reward signal \cite{RLDef1}. \\

In the last part of the current work, humans' learning techniques are analysed from a mathematical point of view in particular with respect to actions performed according to Bayesian Optimization. Different acquisition functions are compared to the humans' ones. Performances obtained by humans in the optimization of black-box functions are finally compared to those obtained by the RL agent in order to better understand possible interconnections among BO, humans' learning and Reinforcement Learning.