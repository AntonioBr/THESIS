\chapter{Introduction}

Nowadays every aspect of life is characterized by the need to make choices. Each choice is conditioned by a variable number of parameters. In many applicative domains (recommendation systems, medical analysis tools, real time game engines, speech recognizers...), this number could be very high.  The possibility to manage in an efficient way such a number of parameters is guaranteed by a significant number of mathematical techniques increasingly performing and refined.  \\

Every decisional problem can be translated into a mathematical model that represents the essence of the problem itself. A crucial step in formulating a model is the construction of the \textit{objective function}. This requires developing a quantitative measure of performance relative to each of the decision makerâ€™s ultimate objectives identified while the problem was being defined.~\cite{HillLieb01} \\

However it is not always possible to define the objective function in advance. It could be unknown or, at least, partially unknown at the time the problem is dealt with. In those cases the optimization process of the objective function takes the name of \textit{black-box optimization}. \\

Mathematically, the problem of finding a global maximizer (or minimizer) of an unknown objective function \textit{f} is formalized as:

\begin{equation}
x^* = \arg \max_{x \in \mathcal{X}} f(x)
\end{equation}

where $\mathcal{X}$ is some design space of interest. In global optimization, $\mathcal{X}$ is often a compact subset of $\mathbb{R}^d$ ~\cite{DBLP:journals/pieee/ShahriariSWAF16}. \\

Bayesian optimization (BO) applied to Gaussian Processes (GPs) represents one of the best known black-box optimization techniques. It represents a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years \cite{Adams2008GaussianPP}. A prior belief over the possible objective functions is defined. After that, as data are observed, the model is sequentially refined via Bayesian posterior updating. The Bayesian posterior represents the updated belief -given data- on the likely objective function \cite{DBLP:journals/pieee/ShahriariSWAF16}. \\

In this thesis, an innovative approach to black-box optimization based on the Reinforcement Learning (RL) technique is proposed. RL is the problem faced by a learner that must behaviour through trial-and-error interactions with a dynamic environment. It can be considered the problem of mapping situations to actions in order to maximize a numerical reward signal \cite{RLDef1}. \\

In the last part of the current work, humans' learning techniques are analysed from a mathematical point of view. Different acquisition functions are compared to the humans' ones. Performances obtained by humans in the optimization of $3d$-black-box functions are finally compared to the ones obtained by the RL agent in order to better understand links between humans' learning and Reinforcement Learning.