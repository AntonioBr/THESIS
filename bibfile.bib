@Book {HillLieb01,
  Title = {Introduction to Operations Research},
  Author = {Frederick S. Hillier and Gerald J. Lieberman},
  Publisher = {McGraw-Hill},
  Year = {2001},
  Address = {New York, NY, USA},
  Edition = {Seventh}
}

@article{DBLP:journals/pieee/ShahriariSWAF16,
	author = {Bobak Shahriari and
	Kevin Swersky and
	Ziyu Wang and
	Ryan P. Adams and
	Nando de Freitas},
	title = {Taking the Human Out of the Loop: {A} Review of Bayesian Optimization},
	journal = {Proceedings of the {IEEE}},
	volume = {104},
	number = {1},
	pages = {148--175},
	year = {2016}
}

@inproceedings{Adams2008GaussianPP,
	title={Gaussian process product models for nonparametric nonstationarity},
	author={Ryan P. Adams and Oliver Stegle},
	booktitle={ICML},
	year={2008}
}

@article{RLDef1,
	author = {Leslie Pack Kaelbling and Michael L. Littman and Andrew W. Moore},
	title = {Reinforcement Learning: A Survey},
	journal = {CoRR},
	volume = {cs.AI/9605103},
	year = {1996}
}

@book{Sigaud:2010:MDP:1841781,
	author = {Sigaud, Olivier and Buffet, Olivier},
	title = {Markov Decision Processes in Artificial Intelligence},
	year = {2010},
	isbn = {1848211678, 9781848211674},
	publisher = {Wiley-IEEE Press},
} 

@BOOK{ SuttonBarto,
	author = {R. S. Sutton and A. G. Barto},
	title = {Reinforcement Learning : An Introduction},
	year = {2018} 
}

@article{ LiMalik,
	author = {Ke Li and Jitendra Malik},
	title = {Learning to Optimize},
	journal = {CoRR},
	volume = {abs/1606.01885},
	year = {2016}
}

@book{Powell,
	author = {Powell, Warren B.},
	title = {Approximate Dynamic Programming: Solving the Curses of Dimensionality (Wiley Series in Probability and Statistics)},
	year = {2007},
	isbn = {0470171553},
	publisher = {Wiley-Interscience},
} 

@inproceedings{Nevmyvaka,
	author = {Nevmyvaka, Yuriy and Feng, Yi and Kearns, Michael},
	title = {Reinforcement Learning for Optimized Trade Execution},
	booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
	series = {ICML '06},
	year = {2006},
	isbn = {1-59593-383-2},
	location = {Pittsburgh, Pennsylvania, USA},
	pages = {673--680},
	numpages = {8},
	url = {http://doi.acm.org/10.1145/1143844.1143929},
	doi = {10.1145/1143844.1143929},
	acmid = {1143929},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@BOOK{ Mitchell,
	author = {Tom M. Mitchell},
	title = {Machine Learning},
	year = {1997}
}

@article{ Maia2009,
	author= {Maia, Tiago V.},
	title={Reinforcement learning, conditioning, and the brain: Successes and challenges},
	journal={Cognitive, Affective {\&} Behavioral Neuroscience},
	year={2009},
	month={Dec},
	pages={343--364},
	issn={1531-135X},
	doi={10.3758/CABN.9.4.343},
	url={https://doi.org/10.3758/CABN.9.4.343}
}

@Book{Put94,
	author={M. Puterman},
	title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
	publisher={John Wiley and Sons},
	year={1994},
	
	volume={},
	series={},
	address={},
	edition={},
	month={},
	note={},
	key={}
}

@article{konstantopoulos2009markov,
	title={Markov Chains and Random Walks},
	author={Konstantopoulos, Takis},
	year={2009}
}

@book{wiering2012reinforcement,
	title={Reinforcement Learning: State-of-the-Art},
	author={Wiering, M. and van Otterlo, M.},
	isbn={9783642276453},
	lccn={2011945323},
	series={Adaptation, Learning, and Optimization},
	url={https://books.google.it/books?id=YPjNuvrJR0MC},
	year={2012},
	publisher={Springer Berlin Heidelberg}
}

@article{watkins1992q,
	title={Q-learning},
	author={Watkins, Christopher JCH and Dayan, Peter},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={279--292},
	year={1992},
	publisher={Springer}
}


