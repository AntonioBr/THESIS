\relax 
\citation{HillLieb01}
\citation{DBLP:journals/pieee/ShahriariSWAF16}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\citation{Adams2008GaussianPP}
\citation{DBLP:journals/pieee/ShahriariSWAF16}
\citation{RLDef1}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\citation{konstantopoulos2009markov}
\citation{Put94}
\citation{wiering2012reinforcement}
\citation{Nevmyvaka}
\citation{Powell}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Markov Decision Process}{3}}
\@writefile{toc}{\contentsline {paragraph}{Markov Decision Process}{3}}
\citation{wiering2012reinforcement}
\citation{Sigaud:2010:MDP:1841781}
\citation{wiering2012reinforcement}
\citation{SuttonBarto}
\@writefile{toc}{\contentsline {paragraph}{States}{4}}
\@writefile{toc}{\contentsline {paragraph}{Actions}{4}}
\@writefile{toc}{\contentsline {paragraph}{Time Steps}{4}}
\@writefile{toc}{\contentsline {paragraph}{Transition Probability}{4}}
\@writefile{toc}{\contentsline {paragraph}{Reward Function}{4}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\citation{wiering2012reinforcement}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Markov decision process\nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}.}}{5}}
\newlabel{fig:MDP}{{2.1}{5}}
\@writefile{toc}{\contentsline {paragraph}{Policy}{5}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Mitchell}
\citation{SuttonBarto}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Different policy families for MDPs\nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}}}{6}}
\newlabel{table:T1}{{2.1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Relationship between the different sets of policies\nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}.}}{6}}
\newlabel{fig:Policies_schema}{{2.2}{6}}
\citation{wiering2012reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Policy application schema\nobreakspace  {}\cite  {SuttonBarto}.}}{7}}
\newlabel{fig:Policy_application_schema}{{2.3}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Optimality : \textbf  {a)} finite horizon, \textbf  {b)} discounted, infinite horizon, \textbf  {c)} average reward}}{7}}
\@writefile{toc}{\contentsline {paragraph}{Discount Factor}{7}}
\@writefile{toc}{\contentsline {paragraph}{Bellman Equation}{8}}
\newlabel{eq:2.2}{{2.3}{8}}
\citation{wiering2012reinforcement}
\newlabel{eq:2.5}{{2.5}{9}}
\@writefile{toc}{\contentsline {paragraph}{Value Iteration vs Policy Iteration}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Value Iteration Schema}}{9}}
\newlabel{fig:ValueiterationPolicy}{{2.5}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Policy Iteration Schema}}{10}}
\newlabel{fig:PolicyIteration}{{2.6}{10}}
\citation{wiering2012reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Solving MDP}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Main differences between model-based and model-free algorithms.}}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Dynamic Programming}{11}}
\citation{SuttonBarto}
\citation{wiering2012reinforcement}
\citation{RLDef1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Reinforcement Learning}{12}}
\citation{LiMalik}
\citation{wiering2012reinforcement}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces A general algorithm for online RL\nobreakspace  {}\cite  {wiering2012reinforcement}}}{13}}
\citation{Sigaud:2010:MDP:1841781}
\citation{SuttonBarto}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces RL's approaches classification.}}{14}}
\newlabel{fig:RL_possibilities_schema}{{2.7}{14}}
\citation{Sigaud:2010:MDP:1841781}
\citation{wiering2012reinforcement}
\citation{wiering2012reinforcement}
\@writefile{toc}{\contentsline {paragraph}{Monte Carlo Methods}{15}}
\newlabel{eq:2.6}{{2.9}{15}}
\citation{Sigaud:2010:MDP:1841781}
\citation{watkins1992q}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Difference between on-policy and off-policy methods.}}{16}}
\@writefile{toc}{\contentsline {paragraph}{Temporal Difference Learning}{16}}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{toc}{\contentsline {paragraph}{Sarsa Algorithm : On-policy TD Control}{17}}
\newlabel{eq:2.12}{{2.15}{17}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces SARSA Algorithm : On-policy TD Control}}{18}}
\@writefile{toc}{\contentsline {paragraph}{Q-learning Algorithm : Off-policy TD Control}{18}}
\newlabel{eq:2.13}{{2.16}{18}}
\@writefile{toc}{\contentsline {paragraph}{SARSA($\lambda $)}{18}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Q-learning Algorithm \nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}}}{19}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces SARSA ($\lambda $) Algorithm \nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}}}{20}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}A Reinforcement Learning Approach to Black-Box Optimization}{23}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{Gaussian Processes}{23}}
\citation{NIPS2012_4522}
\citation{MNDWikipedia}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Multivariate Gaussian Distribution\nobreakspace  {}\cite  {MNDWikipedia}}}{24}}
\newlabel{fig:Multivatiate_Gaussian}{{3.1}{24}}
\@writefile{toc}{\contentsline {paragraph}{Acquisition Functions for Bayesian Optimization}{24}}
\citation{NIPS2012_4522}
\citation{BayesianOptimizationImage}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces 2-$d$ Bayesian Optimization Process Example\nobreakspace  {}\cite  {BayesianOptimizationImage}}}{25}}
\newlabel{fig:BoProcess}{{3.2}{25}}
\@writefile{toc}{\contentsline {paragraph}{An RL Approach To Black-Box Optimization}{26}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces From pixels to real values}}{26}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Angle computation in linear movement case.}}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Linear movement computations.}}{28}}
\newlabel{fig:LMComputations}{{3.3}{28}}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Angle computation in parametric movement case.}}{29}}
\newlabel{PMAlgo}{{7}{29}}
\citation{BURLAPSite}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Parametric movement computations.}}{30}}
\newlabel{fig:PMComputations}{{3.4}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.1}Implementation}{30}}
\citation{BURLAPSite}
\citation{BURLAPSite}
\citation{BURLAPSite}
\citation{BURLAPSite}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces UML Digram of the Java interfaces/classes for an MDP definition.}}{31}}
\newlabel{fig:UMLBurlap}{{3.5}{31}}
\bibdata{bibfile.bib}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Class diagram of RL black-box optimization tool.}}{33}}
\newlabel{fig:RLUMLDiagram}{{3.6}{33}}
\bibcite{Adams2008GaussianPP}{AS08}
\bibcite{BayesianOptimizationImage}{Bay}
\bibcite{BURLAPSite}{BUR}
\bibcite{HillLieb01}{HL01}
\bibcite{RLDef1}{KLM96}
\bibcite{konstantopoulos2009markov}{Kon09}
\bibcite{LiMalik}{LM16}
\bibcite{Mitchell}{Mit97}
\bibcite{MNDWikipedia}{MND}
\bibcite{Nevmyvaka}{NFK06}
\bibcite{Powell}{Pow07}
\bibcite{Put94}{Put94}
\bibcite{Sigaud:2010:MDP:1841781}{SB10}
\bibcite{SuttonBarto}{SB18}
\bibcite{NIPS2012_4522}{SLA12}
\bibcite{DBLP:journals/pieee/ShahriariSWAF16}{SSW{$^{+}$}16}
\bibcite{watkins1992q}{WD92}
\bibcite{wiering2012reinforcement}{WvO12}
\bibstyle{alpha}
