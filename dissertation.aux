\relax 
\citation{HillLieb01}
\citation{DBLP:journals/pieee/ShahriariSWAF16}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\citation{Adams2008GaussianPP}
\citation{DBLP:journals/pieee/ShahriariSWAF16}
\citation{RLDef1}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\citation{konstantopoulos2009markov}
\citation{Put94}
\citation{wiering2012reinforcement}
\citation{Nevmyvaka}
\citation{Powell}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Markov Decision Process}{3}}
\@writefile{toc}{\contentsline {paragraph}{Markov Decision Process}{3}}
\citation{wiering2012reinforcement}
\citation{Sigaud:2010:MDP:1841781}
\citation{wiering2012reinforcement}
\citation{SuttonBarto}
\@writefile{toc}{\contentsline {paragraph}{States}{4}}
\@writefile{toc}{\contentsline {paragraph}{Actions}{4}}
\@writefile{toc}{\contentsline {paragraph}{Time Steps}{4}}
\@writefile{toc}{\contentsline {paragraph}{Transition Probability}{4}}
\@writefile{toc}{\contentsline {paragraph}{Reward Function}{4}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\citation{wiering2012reinforcement}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Markov decision process\nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}.\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:MDP}{{2.1}{5}}
\@writefile{toc}{\contentsline {paragraph}{Policy}{5}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\citation{Mitchell}
\citation{SuttonBarto}
\citation{SuttonBarto}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Different policy families for MDPs\nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}\relax }}{6}}
\newlabel{table:T1}{{2.1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Relationship between the different sets of policies\nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}.\relax }}{6}}
\newlabel{fig:Policies_schema}{{2.2}{6}}
\citation{wiering2012reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Policy application schema\nobreakspace  {}\cite  {SuttonBarto}.\relax }}{7}}
\newlabel{fig:Policy_application_schema}{{2.3}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Optimality : \textbf  {a)} finite horizon, \textbf  {b)} discounted, infinite horizon, \textbf  {c)} average reward\relax }}{7}}
\@writefile{toc}{\contentsline {paragraph}{Discount Factor}{7}}
\@writefile{toc}{\contentsline {paragraph}{Bellman Equation}{8}}
\newlabel{eq:2.2}{{2.3}{8}}
\citation{wiering2012reinforcement}
\newlabel{eq:2.5}{{2.5}{9}}
\@writefile{toc}{\contentsline {paragraph}{Value Iteration vs Policy Iteration}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Value Iteration Schema\relax }}{9}}
\newlabel{fig:ValueiterationPolicy}{{2.5}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Policy Iteration Schema\relax }}{10}}
\newlabel{fig:PolicyIteration}{{2.6}{10}}
\citation{wiering2012reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Solving MDP}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Main differences between model-based and model-free algorithms.\relax }}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Dynamic Programming}{11}}
\citation{SuttonBarto}
\citation{wiering2012reinforcement}
\citation{RLDef1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Reinforcement Learning}{12}}
\citation{LiMalik}
\citation{wiering2012reinforcement}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces A general algorithm for online RL\nobreakspace  {}\cite  {wiering2012reinforcement}\relax }}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces RL's approaches classification.\relax }}{13}}
\newlabel{fig:RL_possibilities_schema}{{2.7}{13}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\citation{SuttonBarto}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{toc}{\contentsline {paragraph}{Monte Carlo Methods}{14}}
\citation{Sigaud:2010:MDP:1841781}
\citation{wiering2012reinforcement}
\citation{wiering2012reinforcement}
\newlabel{eq:2.6}{{2.9}{15}}
\@writefile{toc}{\contentsline {paragraph}{Temporal Difference Learning}{15}}
\citation{Sigaud:2010:MDP:1841781}
\citation{watkins1992q}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Difference between on-policy and off-policy methods.\relax }}{16}}
\@writefile{toc}{\contentsline {paragraph}{Sarsa Algorithm : On-policy TD Control}{16}}
\citation{Sigaud:2010:MDP:1841781}
\newlabel{eq:2.12}{{2.15}{17}}
\@writefile{toc}{\contentsline {paragraph}{Q-learning Algorithm : Off-policy TD Control}{17}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces SARSA Algorithm : On-policy TD Control\relax }}{18}}
\newlabel{eq:2.13}{{2.16}{18}}
\@writefile{toc}{\contentsline {paragraph}{SARSA($\lambda $)}{18}}
\citation{Sigaud:2010:MDP:1841781}
\citation{Sigaud:2010:MDP:1841781}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Q-learning Algorithm \nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}\relax }}{19}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces SARSA ($\lambda $) Algorithm \nobreakspace  {}\cite  {Sigaud:2010:MDP:1841781}\relax }}{20}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}A Reinforcement Learning Approach to Black-Box Optimization}{21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{Gaussian Processes}{21}}
\citation{NIPS2012_4522}
\citation{MNDWikipedia}
\citation{MNDWikipedia}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Multivariate Gaussian Distribution\nobreakspace  {}\cite  {MNDWikipedia}\relax }}{22}}
\newlabel{fig:Multivatiate_Gaussian}{{3.1}{22}}
\@writefile{toc}{\contentsline {paragraph}{Acquisition Functions for Bayesian Optimization}{22}}
\citation{NIPS2012_4522}
\citation{BayesianOptimizationImage}
\citation{BayesianOptimizationImage}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces 2-$d$ Bayesian Optimization Process Example\nobreakspace  {}\cite  {BayesianOptimizationImage}\relax }}{23}}
\newlabel{fig:BoProcess}{{3.2}{23}}
\@writefile{toc}{\contentsline {paragraph}{An RL Approach To Black-Box Optimization}{24}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces From pixels to real values\relax }}{24}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Angle computation in linear movement case.\relax }}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Linear movement computations.\relax }}{26}}
\newlabel{fig:LMComputations}{{3.3}{26}}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Angle computation in parametric movement case.\relax }}{27}}
\newlabel{PMAlgo}{{7}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Parametric movement computations.\relax }}{28}}
\newlabel{fig:PMComputations}{{3.4}{28}}
\citation{BURLAPSite}
\citation{BURLAPSite}
\citation{BURLAPSite}
\citation{BURLAPSite}
\citation{BURLAPSite}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.1}Implementation}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces UML Digram of the Java interfaces/classes for an MDP definition.\relax }}{30}}
\newlabel{fig:UMLBurlap}{{3.5}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Class diagram of RL black-box optimization tool.\relax }}{32}}
\newlabel{fig:RLUMLDiagram}{{3.6}{32}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experimental Setting}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Benchmark}{33}}
\@writefile{toc}{\contentsline {paragraph}{Test Functions}{33}}
\@writefile{toc}{\contentsline {subparagraph}{Himmelblau' s Function}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Original Himmelblau' s Function.\relax }}{34}}
\newlabel{fig:OriginalHimmelblauFunction}{{4.1}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Customized Himmelblau' s Function.\relax }}{35}}
\newlabel{fig:CustomizedHimmelblauFunction}{{4.2}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Contour plot of customized version of Himmelblau' s Function.\relax }}{36}}
\newlabel{fig:ContourPlotCustomizedHimmelblauFunction}{{4.3}{36}}
\@writefile{toc}{\contentsline {subparagraph}{Paraboloid of Revolution}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Original Paraboloid of Revolution.\relax }}{37}}
\newlabel{fig:OriginalParaboloidOfRevolution}{{4.4}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Customized Paraboloid of Revolution.\relax }}{38}}
\newlabel{fig:CustomizedParaboloidOfRevolution}{{4.5}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Contour plot of customized Parabolic Function.\relax }}{39}}
\newlabel{fig:ContourPlotCustomizedParabolicFunction}{{4.6}{39}}
\@writefile{toc}{\contentsline {subparagraph}{Beale Function}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Original Beale Function.\relax }}{40}}
\newlabel{fig:OriginalBealeFunction}{{4.7}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Customized Beale Function.\relax }}{41}}
\newlabel{fig:CustomizedBealeFunction}{{4.8}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Contour plot of customized Beale Function.\relax }}{42}}
\newlabel{fig:ContourPlotCustomizedBealeFunction}{{4.9}{42}}
\@writefile{toc}{\contentsline {subparagraph}{Styblinski-Tang Revised Function}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Original Styblinski Function.\relax }}{43}}
\newlabel{fig:OriginalStyblinskiFunction}{{4.10}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Customized Styblinski Function.\relax }}{44}}
\newlabel{fig:CustomizedStyblinskiFunction}{{4.11}{44}}
\bibdata{bibfile.bib}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Contour plot of customized Styblinski Function.\relax }}{45}}
\newlabel{fig:ContourStyblinskiFunction}{{4.12}{45}}
\bibcite{Adams2008GaussianPP}{AS08}
\bibcite{BayesianOptimizationImage}{Bay}
\bibcite{BURLAPSite}{BUR}
\bibcite{HillLieb01}{HL01}
\bibcite{RLDef1}{KLM96}
\bibcite{konstantopoulos2009markov}{Kon09}
\bibcite{LiMalik}{LM16}
\bibcite{Mitchell}{Mit97}
\bibcite{MNDWikipedia}{MND}
\bibcite{Nevmyvaka}{NFK06}
\bibcite{Powell}{Pow07}
\bibcite{Put94}{Put94}
\bibcite{Sigaud:2010:MDP:1841781}{SB10}
\bibcite{SuttonBarto}{SB18}
\bibcite{NIPS2012_4522}{SLA12}
\bibcite{DBLP:journals/pieee/ShahriariSWAF16}{SSW{$^{+}$}16}
\bibcite{watkins1992q}{WD92}
\bibcite{wiering2012reinforcement}{WvO12}
\bibstyle{alpha}
